* Your object
From my understanding, your objectives are:

- Compare `csv` files in 2 version folders, all filenames are same;
- filenames contain date information;
- For each file:
  - the first row of `csv` files is columns title;
  - the rest rows are data to compare;
  - their is no column can be used as an nature index.
- The program should save result in file rather than print to screen;

* some reference

** Filter files by name pattern

Use fnmatch.filter(alist, glob_name_pattern) to return a list of name with some glob pattern, i.e.

`fnmatch.filter(os.listdir(), '*.csv')`

return all .csv file in current dir.

** Transfer string to date (pd.to_dataframe)

You can use pandas general function to convert string or ymd interger to date data.
This general function from pandas accept several sequence arguments as input:

- sequence of int, ordered by "year", "month", "day"
  if a DataFrame is provided,
- string of date in localized format
  to set your local from your platform default, import locale module and set as follow:

```
import locale
locale.setlocale(locale.ALL='')
```

** Nested `for...` Loop (causing slow)

When iter over 2 iterable with same size (length), you use a nested `for...` structure, that costs n*n times of loop. There's 574 csv files in each version folder, so it use 574*574 loop, this is main cause of slow.
Instead, use zip() to pair iterable with same size, then iter on the new zip object, this costs n times of loop and save n*(n-1) times from nested loop.

```
for old, new in zip(olds, news):
    my_func_to_compare(old, new)  # loop body here
```

* example code

It's is quite long go download from github:
https://github.com/DiligentDolphin/stackoverflow_answer
and find the folder with your quesion id: 72223986
 
** TL;DR;
- run `gen_test_material.py`, this generate a test material for the `example.py`
- edit `example.py` if you change path in `gen` file
- locate function `test_multiple_files`, change path_new, path_old to corresponding dir
- change the dict `kwargs_read_csv` to pass in the `pd.read_csv` keywords arguments
- change variable `result_out_path` to choose compare output csv file path
- run `example.py`

** Explain

*** Compare file to file

I assume your requirement do not includes crossing file compare, so there is no need to concat all csv in one dir together then compared to the other folder. Instead, compare by filename and found if that name also exists in other folder, then compare then in detail.

*** Standarize DataFrame

Once you read from csv, reshape all its columns to index by pd.stack, thus create a 3-columns fixed DataFrame: (Index, Column, Value), which later you can use to compare DataFrame with same Index / Column name but not same shape or sequence.

*** When File not exist

In gen_test_material, I make both NewVersion and OldVersion dir lacking some filenames from each other, to simulate when some version of file only exists in one dir. In this case, construct a None-filled DataFrame with the same shape, then compare function will return all values as diff.
